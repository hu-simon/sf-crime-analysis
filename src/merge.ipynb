{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "sfcrime",
   "display_name": "sfcrime"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the two datasets.\n",
    "dataset1_path = \"/Users/administrator/Documents/Projects/sf-crime-exploration/data/SFPD_Crime_Data_2003_2018.csv\"\n",
    "dataset2_path = \"/Users/administrator/Documents/Projects/sf-crime-exploration/data/SFPD_Crime_Data_2018_Present.csv\"\n",
    "\n",
    "dataset1 = pd.read_csv(dataset1_path)\n",
    "dataset2 = pd.read_csv(dataset2_path)\n",
    "\n",
    "# Define the subsets of the data that we want to preserve.\n",
    "subset1 = [\"Category\", \"DayOfWeek\", \"Date\", \"Time\", \"PdDistrict\", \"X\", \"Y\"]\n",
    "subset2 = [\n",
    "    \"Incident Category\", \n",
    "    \"Incident Day of Week\",\n",
    "    \"Incident Date\",\n",
    "    \"Incident Time\",\n",
    "    \"Police District\", \n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "]\n",
    "master_columns = [\"Date\", \"Time\", \"Day of Week\", \"Category\", \"District\", \"Latitude\", \"Longitude\"]\n",
    "\n",
    "# Define the dictionaries that are used for renaming the categories.\n",
    "subset1_rename = {\"DayOfWeek\": \"Day of Week\", \"PdDistrict\": \"District\", \"X\": \"Longitude\", \"Y\": \"Latitude\",}\n",
    "subset2_rename = {\n",
    "    \"Incident Category\": \"Category\", \n",
    "    \"Incident Day of Week\": \"Day of Week\", \n",
    "    \"Incident Date\": \"Date\", \n",
    "    \"Incident Time\": \"Time\", \n",
    "    \"Police District\": \"District\",\n",
    "}"
   ]
  },
  {
   "source": [
    "#### Modify Dataset 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f6aaa6ed535f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Capitalize the entries in the \"District\" column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Narrow down to the subset of columns that we are interested in.\n",
    "dataset1 = dataset1[subset1]\n",
    "\n",
    "# Drop null/invalid values.\n",
    "dataset1.dropna(inplace=True)\n",
    "\n",
    "# Rename the columns.\n",
    "dataset1.rename(columns=subset1_rename, inplace=True)\n",
    "\n",
    "# Remove any \"Out of SF\" entries if they exist.\n",
    "dataset1[\"District\"] = dataset1[\"District\"][dataset1[\"District\"] != \"Out of SF\"]\n",
    "\n",
    "# Capitalize the entries in the \"Day of Week\" column.\n",
    "dataset1[\"Day of Week\"] = dataset1[\"Day of Week\"].apply(lambda x: x.upper())\n",
    "\n",
    "# Capitalize the entries in the \"Category\" column.\n",
    "dataset1[\"Category\"] = dataset1[\"Category\"].apply(lambda x: x.upper())\n",
    "\n",
    "# Capitalize the entries in the \"District\" column.\n",
    "dataset1[\"District\"] = dataset1[\"District\"].apply(lambda x: x.upper())"
   ]
  },
  {
   "source": [
    "#### Modify Dataset 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'upper'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2840623b7557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Capitalize the entries in the \"District\" column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/sfcrime/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4198\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4200\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2840623b7557>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Capitalize the entries in the \"District\" column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdataset2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"District\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'upper'"
     ]
    }
   ],
   "source": [
    "# Narrow down to the subset of columns that we are interested in.\n",
    "dataset2 = dataset2[subset2]\n",
    "\n",
    "# Drop null/invalid values.\n",
    "dataset2.dropna(inplace=True)\n",
    "\n",
    "# Rename the columns.\n",
    "dataset2.rename(columns=subset2_rename, inplace=True)\n",
    "\n",
    "# Remove any \"Out of SF\" entries if they exist.\n",
    "dataset2[\"District\"] = dataset2[\"District\"][dataset2[\"District\"] != \"Out of SF\"]\n",
    "\n",
    "# Capitalize the entries in the \"Day of Week\" column.\n",
    "dataset2[\"Day of Week\"] = dataset2[\"Day of Week\"].apply(lambda x: x.upper())\n",
    "\n",
    "# Capitalize the entries in the \"Category\" column.\n",
    "dataset2[\"Category\"] = dataset2[\"Category\"].apply(lambda x: x.upper())\n",
    "\n",
    "# Capitalize the entries in the \"District\" column.\n",
    "dataset2[\"District\"] = dataset2[\"District\"].apply(lambda x: x.upper())"
   ]
  },
  {
   "source": [
    "#### Merge the Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use concat to merge the two datasets.\n",
    "datasets = [dataset1, dataset2]\n",
    "dataset = pd.concat(datasets, ignore_index=True)\n",
    "\n",
    "# Reorder the columns.\n",
    "dataset = dataset[master_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Date   Time Day of Week           Category  District  \\\n",
       "2534373  2020/08/15  20:44    SATURDAY      Larceny Theft   Central   \n",
       "2534374  2020/08/15  08:00    SATURDAY       Non-Criminal  Northern   \n",
       "2534375  2020/08/15  15:47    SATURDAY           Burglary   Central   \n",
       "2534376  2020/08/15  21:52    SATURDAY  Recovered Vehicle   Taraval   \n",
       "2534377  2020/08/15  23:50    SATURDAY           Burglary   Central   \n",
       "\n",
       "          Latitude   Longitude  \n",
       "2534373  37.788808 -122.411886  \n",
       "2534374  37.792263 -122.436204  \n",
       "2534375  37.788293 -122.408402  \n",
       "2534376  37.741234 -122.474494  \n",
       "2534377  37.788293 -122.408402  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>Day of Week</th>\n      <th>Category</th>\n      <th>District</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2534373</th>\n      <td>2020/08/15</td>\n      <td>20:44</td>\n      <td>SATURDAY</td>\n      <td>Larceny Theft</td>\n      <td>Central</td>\n      <td>37.788808</td>\n      <td>-122.411886</td>\n    </tr>\n    <tr>\n      <th>2534374</th>\n      <td>2020/08/15</td>\n      <td>08:00</td>\n      <td>SATURDAY</td>\n      <td>Non-Criminal</td>\n      <td>Northern</td>\n      <td>37.792263</td>\n      <td>-122.436204</td>\n    </tr>\n    <tr>\n      <th>2534375</th>\n      <td>2020/08/15</td>\n      <td>15:47</td>\n      <td>SATURDAY</td>\n      <td>Burglary</td>\n      <td>Central</td>\n      <td>37.788293</td>\n      <td>-122.408402</td>\n    </tr>\n    <tr>\n      <th>2534376</th>\n      <td>2020/08/15</td>\n      <td>21:52</td>\n      <td>SATURDAY</td>\n      <td>Recovered Vehicle</td>\n      <td>Taraval</td>\n      <td>37.741234</td>\n      <td>-122.474494</td>\n    </tr>\n    <tr>\n      <th>2534377</th>\n      <td>2020/08/15</td>\n      <td>23:50</td>\n      <td>SATURDAY</td>\n      <td>Burglary</td>\n      <td>Central</td>\n      <td>37.788293</td>\n      <td>-122.408402</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/Users/administrator/Documents/Projects/sf-crime-exploration/data/SFPD_Crime_Data_Full.csv\"\n",
    "dataset.to_csv(save_path, index=False)"
   ]
  }
 ]
}